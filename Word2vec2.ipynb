{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --*-- encoding:utf-8 --*--\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "def loadfile():\n",
    "    neg = pd.read_excel('./neg1.xls', header=None, index=None)\n",
    "    pos = pd.read_excel('./pos1.xls', header=None, index=None)\n",
    "    #merge all data\n",
    "    neg = np.array(neg[0])\n",
    "    pos = np.array(pos[0])\n",
    "    return neg,pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = loadfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating set of disused words\n",
    "def getstopword(stopwordPath):\n",
    "    stoplist = set()\n",
    "    for line in stopwordPath:\n",
    "        stoplist.add(line.strip())\n",
    "        # print line.strip()\n",
    "    return stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the sentence and remove the disused words\n",
    "def wordsege(text):\n",
    "    # get disused words set\n",
    "    stopwordPath = open('./stopwords(ch).txt', 'r')\n",
    "    stoplist = getstopword(stopwordPath)\n",
    "    stopwordPath.close()\n",
    "\n",
    "    # divide the sentence and remove the disused words with jieba,return list\n",
    "    text_list = []\n",
    "    for document in text:\n",
    "\n",
    "        seg_list = jieba.cut(document.strip())\n",
    "        fenci = []\n",
    "\n",
    "        for item in seg_list:\n",
    "            if item not in stoplist and re.match(r'-?\\d+\\.?\\d*', item) == None and len(item.strip()) > 0:\n",
    "                fenci.append(item)\n",
    "        # if the word segmentation of the sentence is null,the label of the sentence should be deleted accordingly\n",
    "        if len(fenci) > 0:\n",
    "            text_list.append(fenci)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(neg, pos):\n",
    "    neg_sege = wordsege(neg)\n",
    "    pos_sege = wordsege(pos)\n",
    "    combined = np.concatenate((pos_sege,neg_sege))\n",
    "    # generating label and meging label data\n",
    "    y = np.concatenate((np.ones(len(pos_sege), dtype=int), np.zeros(len(neg_sege), dtype=int)))\n",
    "    return combined,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\chenx\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.945 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "combined,y = tokenizer(neg, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(combined, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(combined, size=128, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_size 指的是我们本身vector的size\n",
    "def transform_to_matrix(x, padding_size=256, vec_size=128):\n",
    "    res = []\n",
    "    for sen in x:\n",
    "        matrix = []\n",
    "        for i in range(padding_size):\n",
    "            try:\n",
    "                matrix.append(model[sen[i]].tolist())\n",
    "            except:\n",
    "                # 这里有两种except情况，\n",
    "                # 1. 这个单词找不到\n",
    "                # 2. sen没那么长\n",
    "                # 不管哪种情况，我们直接贴上全是0的vec\n",
    "                matrix.append([0] * vec_size)\n",
    "        res.append(matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x_train = transform_to_matrix(x_train)\n",
    "x_test = transform_to_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5467, 256, 128)\n",
      "(2344, 256, 128)\n"
     ]
    }
   ],
   "source": [
    "# 搞成np的数组，便于处理\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# 看看数组的大小\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.73754823, -0.67077446,  0.52392203, ..., -0.29133576,\n",
       "          0.53854764, -0.32955688],\n",
       "        [-0.49326193, -0.37904742,  0.36180976, ...,  0.46447107,\n",
       "          0.00639839,  0.29083756],\n",
       "        [-0.83388954,  0.23402041,  0.43273127, ...,  0.14682986,\n",
       "          0.11302818,  0.83645195],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.48475784,  0.8911072 , -0.70936328, ...,  0.17108437,\n",
       "         -0.63081181, -1.88813722],\n",
       "        [-0.12395851,  0.31090653,  0.05899351, ...,  0.07256895,\n",
       "          0.03908725,  0.11025846],\n",
       "        [-0.30392766, -0.04698357,  0.26532772, ...,  0.72936624,\n",
       "         -0.09928361, -0.07671563],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.29020506,  0.29030743,  0.1124137 , ..., -0.00293569,\n",
       "          0.07444663,  0.11861005],\n",
       "        [-0.32992345,  0.35227448,  0.10530256, ..., -0.03359942,\n",
       "          0.09775906,  0.1081524 ],\n",
       "        [-0.99406987,  0.48154747, -0.11614408, ...,  0.02781554,\n",
       "          0.06418751, -1.05850458],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.44965672,  0.29106101,  0.21654804, ...,  0.06911326,\n",
       "          0.10351588,  0.23502006],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.12636422,  0.30757084, -0.13537252, ...,  0.13968223,\n",
       "         -0.04590899, -0.37715003],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.12510853,  0.24138686, -0.0233727 , ...,  0.11369035,\n",
       "          0.05142482,  0.23231174],\n",
       "        [-0.27575028,  0.14440879,  0.04595879, ...,  0.23502575,\n",
       "          0.14796947,  0.28762314],\n",
       "        [ 0.25970364,  0.18601558,  0.22600706, ...,  0.24211527,\n",
       "         -0.33449954,  0.13727103],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.99406987,  0.48154747, -0.11614408, ...,  0.02781554,\n",
       "          0.06418751, -1.05850458],\n",
       "        [-0.15460703,  0.23015724,  0.00629415, ...,  0.05315042,\n",
       "          0.02070372, -0.03640493],\n",
       "        [-0.48475784,  0.8911072 , -0.70936328, ...,  0.17108437,\n",
       "         -0.63081181, -1.88813722],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5467,)\n",
      "(2344,)\n"
     ]
    }
   ],
   "source": [
    "# 搞成np的数组，便于处理\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 看看数组的大小\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./x1_train.npy', x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./x1_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5467, 256, 128)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./x1_test.npy', x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('./x1_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2344, 256, 128)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5467, 1, 256, 128, 1)\n",
      "(2344, 1, 256, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1], x_test.shape[2], 1)\n",
    "#通过print(X_test)观察与前者的区别，就是多了一个括号\n",
    "print(x_train.shape) \n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./y1_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./y1_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
